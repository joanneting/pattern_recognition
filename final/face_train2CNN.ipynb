{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'LinTzuTing', 1: 'abarnvbtwb', 2: 'Theodora', 3: 'aelfnikyqj'}\n",
      "+++++++===\n",
      "./face/\n",
      "(13388, 64, 64, 3)\n",
      "[1 1 1 ... 2 2 2]\n",
      "13388\n",
      "64 64 3\n",
      "9371 train samples\n",
      "4017 valid samples\n",
      "6694 test samples\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 22, 22, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "average_pool (GlobalAverageP (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 354,308\n",
      "Trainable params: 354,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 22, 22, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "average_pool (GlobalAverageP (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 354,308\n",
      "Trainable params: 354,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "9371\n",
      "Epoch 1/5\n",
      "293/293 [==============================] - 86s 293ms/step - loss: 1.1113 - acc: 0.5540 - val_loss: 1.0962 - val_acc: 0.5527\n",
      "Epoch 2/5\n",
      "293/293 [==============================] - 85s 289ms/step - loss: 1.0978 - acc: 0.5549 - val_loss: 1.0954 - val_acc: 0.5527\n",
      "Epoch 3/5\n",
      "293/293 [==============================] - 82s 279ms/step - loss: 1.0998 - acc: 0.5549 - val_loss: 1.0951 - val_acc: 0.5527\n",
      "Epoch 4/5\n",
      "293/293 [==============================] - 84s 288ms/step - loss: 1.0991 - acc: 0.5549 - val_loss: 1.0952 - val_acc: 0.5527\n",
      "Epoch 5/5\n",
      "293/293 [==============================] - 88s 301ms/step - loss: 1.0980 - acc: 0.5549 - val_loss: 1.0941 - val_acc: 0.5527\n",
      "{0: 'LinTzuTing', 1: 'abarnvbtwb', 2: 'Theodora', 3: 'aelfnikyqj'}\n",
      "+++++++===\n",
      "./face/\n",
      "(16735, 64, 64, 3)\n",
      "[1 1 1 ... 2 2 2]\n",
      "16735\n",
      "64 64 3\n",
      "11714 train samples\n",
      "5021 valid samples\n",
      "8368 test samples\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 22, 22, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 2, 2, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "average_pool (GlobalAverageP (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 354,308\n",
      "Trainable params: 354,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "======dataset======\n",
      "<__main__.Dataset object at 0x00000157C54CD520>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11714\n",
      "Epoch 1/5\n",
      "367/367 [==============================] - 88s 240ms/step - loss: 1.1115 - acc: 0.5512 - val_loss: 1.0887 - val_acc: 0.5595\n",
      "Epoch 2/5\n",
      "367/367 [==============================] - 64s 175ms/step - loss: 1.1015 - acc: 0.5520 - val_loss: 1.0926 - val_acc: 0.5595\n",
      "Epoch 3/5\n",
      "367/367 [==============================] - 65s 176ms/step - loss: 1.1026 - acc: 0.5520 - val_loss: 1.0898 - val_acc: 0.5595\n",
      "Epoch 4/5\n",
      "367/367 [==============================] - 63s 171ms/step - loss: 1.1008 - acc: 0.5520 - val_loss: 1.0904 - val_acc: 0.5595\n",
      "Epoch 5/5\n",
      "367/367 [==============================] - 61s 166ms/step - loss: 1.0988 - acc: 0.5520 - val_loss: 1.0891 - val_acc: 0.5595\n",
      "{0: 'LinTzuTing', 1: 'abarnvbtwb', 2: 'Theodora', 3: 'aelfnikyqj'}\n",
      "+++++++===\n",
      "./face/\n",
      "(20082, 64, 64, 3)\n",
      "[1 1 1 ... 2 2 2]\n",
      "20082\n",
      "64 64 3\n",
      "14057 train samples\n",
      "6025 valid samples\n",
      "10041 test samples\n",
      "314/314 [==============================] - 4s 14ms/step - loss: 1.0944 - acc: 0.5554\n",
      "acc: 55.54%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D,GlobalAveragePooling2D,BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# import os\n",
    "# import sys\n",
    "# sys.path.insert(0, os.path.abspath('../final/'))\n",
    "\n",
    "# from load_dataset import load_dataset, resize_image, IMAGE_SIZE\n",
    "import Ipynb_importer\n",
    "from load_dataset import load_dataset, resize_image, IMAGE_SIZE\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, path_name):\n",
    "        #訓練集\n",
    "        self.train_images = None\n",
    "        self.train_labels = None\n",
    "        \n",
    "        #驗證集\n",
    "        self.valid_images = None\n",
    "        self.valid_labels = None\n",
    "        \n",
    "        #測試集\n",
    "        self.test_images  = None            \n",
    "        self.test_labels  = None\n",
    "        \n",
    "        #資料集載入路徑\n",
    "        self.path_name    = path_name\n",
    "        \n",
    "        #當前庫採用的維度順序\n",
    "        self.input_shape = None\n",
    "        \n",
    "    #載入資料集並按照交叉驗證的原則劃分資料集並進行相關預處理工作\n",
    "    def load(self, img_rows = IMAGE_SIZE, img_cols = IMAGE_SIZE, \n",
    "             img_channels = 3, nb_classes =4):\n",
    "        peoples = {}\n",
    "        with open('./faceDetail.csv', newline='') as csvfile:\n",
    "                  # 讀取 CSV 檔案內容\n",
    "            rows = csv.reader(csvfile)\n",
    "            for row in rows :\n",
    "                if(row[1] == 'label') :\n",
    "                    continue\n",
    "                peoples[int(row[1])] = row[0]\n",
    "        nb_classes = len(peoples)\n",
    "        print(peoples)\n",
    "        #載入資料集到記憶體\n",
    "        images, labels = load_dataset(self.path_name)        \n",
    "        \n",
    "        train_images, valid_images, train_labels, valid_labels = train_test_split(images, labels, test_size = 0.3, random_state = random.randint(0, 100))        \n",
    "        _, test_images, _, test_labels = train_test_split(images, labels, test_size = 0.5, random_state = random.randint(0, 100))                \n",
    "        \n",
    "        #當前的維度順序如果為'th'，則輸入圖片資料時的順序為：channels,rows,cols，否則:rows,cols,channels\n",
    "#                          channels_first                channels,width,height    width、height、channels\n",
    "        #這部分程式碼就是根據keras庫要求的維度順序重組訓練資料集\n",
    "        if K.image_data_format() == 'channels_first':# 高版本使用\n",
    "#         if K.image_dim_ordering() == 'th':# 低版本使用\n",
    "            train_images = train_images.reshape(train_images.shape[0], img_channels, img_rows, img_cols)\n",
    "            valid_images = valid_images.reshape(valid_images.shape[0], img_channels, img_rows, img_cols)\n",
    "            test_images = test_images.reshape(test_images.shape[0], img_channels, img_rows, img_cols)\n",
    "            self.input_shape = (img_channels, img_rows, img_cols)            \n",
    "        else:\n",
    "            print(img_rows, img_cols, img_channels);\n",
    "            train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, img_channels)\n",
    "            valid_images = valid_images.reshape(valid_images.shape[0], img_rows, img_cols, img_channels)\n",
    "            test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, img_channels)\n",
    "            self.input_shape = (img_rows, img_cols, img_channels)            \n",
    "            \n",
    "        #輸出訓練集、驗證集、測試集的數量\n",
    "        print(train_images.shape[0], 'train samples')\n",
    "        print(valid_images.shape[0], 'valid samples')\n",
    "        print(test_images.shape[0], 'test samples')\n",
    "\n",
    "        #我們的模型使用categorical_crossentropy作為損失函式，因此需要根據類別數量nb_classes將\n",
    "        #類別標籤進行one-hot編碼使其向量化，在這裡我們的類別只有兩種，經過轉化後標籤資料變為二維\n",
    "        train_labels = np_utils.to_categorical(train_labels, nb_classes)                        \n",
    "        valid_labels = np_utils.to_categorical(valid_labels, nb_classes)            \n",
    "        test_labels = np_utils.to_categorical(test_labels, nb_classes)                        \n",
    "\n",
    "        #畫素資料浮點化以便歸一化\n",
    "        train_images = train_images.astype('float32')            \n",
    "        valid_images = valid_images.astype('float32')\n",
    "        test_images = test_images.astype('float32')\n",
    "\n",
    "        #將其歸一化,影象的各畫素值歸一化到0~1區間\n",
    "        train_images /= 255\n",
    "        valid_images /= 255\n",
    "        test_images /= 255            \n",
    "\n",
    "        self.train_images = train_images\n",
    "        self.valid_images = valid_images\n",
    "        self.test_images  = test_images\n",
    "        self.train_labels = train_labels\n",
    "        self.valid_labels = valid_labels\n",
    "        self.test_labels  = test_labels\n",
    "            \n",
    "#CNN網路模型類            \n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.model = None \n",
    "        \n",
    "    #建立模型\n",
    "    def build_model(self, dataset, nb_classes = 4):\n",
    "        #構建一個空的網路模型，它是一個線性堆疊模型，各神經網路層會被順序新增，專業名稱為序貫模型或線性堆疊模型\n",
    "        self.model = Sequential() \n",
    "        peoples = {}\n",
    "        with open('./faceDetail.csv', newline='') as csvfile:\n",
    "                  # 讀取 CSV 檔案內容\n",
    "            rows = csv.reader(csvfile)\n",
    "            for row in rows :\n",
    "                if(row[1] == 'label') :\n",
    "                    continue\n",
    "                peoples[int(row[1])] = row[0]\n",
    "        nb_classes = len(peoples)\n",
    "        #以下程式碼將順序新增CNN網路需要的各層，一個add就是一個網路層\n",
    "        #                           (輸出維度,)\n",
    "          \n",
    "        self.model.add(Convolution2D(32, 3, 3,padding='same', \n",
    "                                     input_shape = dataset.input_shape))    #1 2維卷積層\n",
    "        self.model.add(Activation('relu'))                                  #2 啟用函式層\n",
    "#         self.model.add(ResNet50(include_top=False, weights='imagenet', input_tensor=None,pooling='avg', input_shape = dataset.input_shape))\n",
    "        self.model.add(Activation('relu'))   \n",
    "        self.model.add(Dropout(0.5))\n",
    "        \n",
    "#         self.model.add(Convolution2D(32, 3, 3))                             #3 2維卷積層                             \n",
    "#         self.model.add(Activation('relu'))                                  #4 啟用函式層\n",
    "        \n",
    "#         self.model.add(MaxPooling2D(pool_size=(2, 2)))                      #5 池化層\n",
    "#         self.model.add(Dropout(0.))                                       #6 Dropout層\n",
    "\n",
    "        self.model.add(Convolution2D(64, 3, 3, padding='same'))         #7  2維卷積層\n",
    "        self.model.add(Activation('relu'))                                  #8  啟用函式層\n",
    "        \n",
    "        self.model.add(Convolution2D(64, 3, 3))                             #9  2維卷積層\n",
    "        self.model.add(Activation('relu'))                                  #10 啟用函式層\n",
    "        \n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))                      #11 池化層\n",
    "        self.model.add(Dropout(0.25))                                       #12 Dropout層\n",
    "        self.model.add(GlobalAveragePooling2D(name='average_pool'))\n",
    "        self.model.add(Flatten())                                           #13 Flatten層\n",
    "        self.model.add(Dense(512))                                          #14 Dense層,又被稱作全連線層\n",
    "        self.model.add(Activation('relu'))                                  #15 啟用函式層   \n",
    "#         self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(0.5)) \n",
    "        self.model.add(Dense(512))                                          #14 Dense層,又被稱作全連線層\n",
    "        self.model.add(Activation('relu'))         \n",
    "        \n",
    "        \n",
    "        self.model.add(Dropout(0.5))                                        #16 Dropout層\n",
    "#         self.model.add(Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))) \n",
    "        \n",
    "        self.model.add(Dense(nb_classes))                                   #17 Dense層\n",
    "        self.model.add(Activation('softmax'))                               #18 分類層，輸出最終結果\n",
    "        \n",
    "        self.model.summary()\n",
    "#     def scheduler(epoch):\n",
    "#     # 前5个epoch学习率保持不变，5个epoch后学习率按比例衰减\n",
    "#     if epoch < 5:\n",
    "#         return 0.001\n",
    "#     else:\n",
    "#         lr = 0.001 * tf.math.exp(0.1 * (5 - epoch))\n",
    "#         return lr.numpy()\n",
    "    \n",
    "\n",
    "    #訓練模型\n",
    "    def train(self, dataset, batch_size = 32, nb_epoch = 5, data_augmentation = True):\n",
    "        \n",
    "        learning_rate = 0.001\n",
    "        decay_rate = 1e-6\n",
    "        \n",
    "#         self.model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=learning_rate,  decay=decay_rate, amsgrad=True), metrics=['acc'])\n",
    "        self.model.compile(loss='categorical_crossentropy',optimizer=Adam(), metrics=['acc'])\n",
    "        #輸出模型概況\n",
    "#         sgd = SGD(lr = 0.01, decay = 1e-6, \n",
    "#                   momentum = 0.9, nesterov = True) #採用SGD+momentum的優化器進行訓練，首先生成一個優化器物件  \n",
    "#         self.model.compile(loss='categorical_crossentropy',\n",
    "#                            optimizer=sgd,\n",
    "#                            metrics=['accuracy'])   #完成實際的模型配置工作\n",
    "        \n",
    "        #不使用資料提升，所謂的提升就是從我們提供的訓練資料中利用旋轉、翻轉、加噪聲等方法創造新的\n",
    "        #訓練資料，有意識的提升訓練資料規模，增加模型訓練量\n",
    "        if not data_augmentation:            \n",
    "            self.model.fit(dataset.train_images,\n",
    "                           dataset.train_labels,\n",
    "                           batch_size = batch_size,\n",
    "                           epochs = nb_epoch,\n",
    "                           validation_data = (dataset.valid_images, dataset.valid_labels),\n",
    "                           shuffle = True)\n",
    "        #使用實時資料提升\n",
    "        else:            \n",
    "            #定義資料生成器用於資料提升，其返回一個生成器物件datagen，datagen每被呼叫一\n",
    "            #次其生成一組資料（順序生成），節省記憶體，其實就是python的資料生成器\n",
    "            datagen = ImageDataGenerator(\n",
    "                featurewise_center = False,             #是否使輸入資料去中心化（均值為0），\n",
    "                samplewise_center  = False,             #是否使輸入資料的每個樣本均值為0\n",
    "                featurewise_std_normalization = False,  #是否資料標準化（輸入資料除以資料集的標準差）\n",
    "                samplewise_std_normalization  = False,  #是否將每個樣本資料除以自身的標準差\n",
    "                zca_whitening = False,                  #是否對輸入資料施以ZCA白化\n",
    "                rotation_range = 10,                    #資料提升時圖片隨機轉動的角度(範圍為0～180)\n",
    "                rescale = 1./255,\n",
    "                width_shift_range  = 0.1,               #資料提升時圖片水平偏移的幅度（單位為圖片寬度的佔比，0~1之間的浮點數）\n",
    "                height_shift_range = 0.1,               #同上，只不過這裡是垂直\n",
    "                horizontal_flip = False,                 #是否進行隨機水平翻轉\n",
    "                vertical_flip = False,                   #是否進行隨機垂直翻轉\n",
    "                fill_mode = 'constant')                 \n",
    "\n",
    "            #計算整個訓練樣本集的數量以用於特徵值歸一化、ZCA白化等處理\n",
    "            datagen.fit(dataset.train_images) \n",
    "            test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "            test_datagen.fit(dataset.valid_images)\n",
    "            print(dataset.train_images.shape[0])\n",
    "            #利用生成器開始訓練模型\n",
    "#             self.model.fit(dataset.train_images,\n",
    "#                            dataset.train_labels,\n",
    "#                            batch_size = batch_size,\n",
    "#                            epochs = nb_epoch,\n",
    "#                            validation_data = (dataset.valid_images, dataset.valid_labels),\n",
    "#                            shuffle = True)\n",
    "           \n",
    "#             early_stopping = EarlyStopping(monitor='val_loss',patience=100) \n",
    "#             reduce_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "            self.model.fit(datagen.flow(dataset.train_images, dataset.train_labels,\n",
    "                                                   batch_size = batch_size),\n",
    "#                             steps_per_epoch = dataset.train_images.shape[0]/batch_size,\n",
    "                            epochs = nb_epoch,\n",
    "                            validation_data = test_datagen.flow(dataset.valid_images, dataset.valid_labels,batch_size = batch_size),\n",
    "                            shuffle = True)    \n",
    "#              self.model.fit(datagen.flow(dataset.train_images, dataset.train_labels,\n",
    "#                                                    batch_size = batch_size),\n",
    "# #                             steps_per_epoch = dataset.train_images.shape[0]/batch_size,\n",
    "#                             epochs = nb_epoch,\n",
    "#                             validation_data = (dataset.valid_images, dataset.valid_labels),\n",
    "#                             shuffle = True)    \n",
    "    \n",
    "    MODEL_PATH = './haarcascade2.face.model.h5'\n",
    "    def save_model(self, file_path = MODEL_PATH):\n",
    "         self.model.save(file_path)\n",
    " \n",
    "    def load_model(self, file_path = MODEL_PATH):\n",
    "         self.model = load_model(file_path)\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "         score = self.model.evaluate(dataset.test_images, dataset.test_labels, verbose = 1)\n",
    "         print(\"%s: %.2f%%\" % (self.model.metrics_names[1], score[1] * 100))\n",
    "\n",
    "    #識別人臉\n",
    "    def face_predict(self, image):    \n",
    "        #依然是根據後端系統確定維度順序\n",
    "        if K.image_data_format() == 'channels_first' and image.shape != (1, 3, IMAGE_SIZE, IMAGE_SIZE):\n",
    "            image = resize_image(image)                             #尺寸必須與訓練集一致都應該是IMAGE_SIZE x IMAGE_SIZE\n",
    "            image = image.reshape((1, 3, IMAGE_SIZE, IMAGE_SIZE))   #與模型訓練不同，這次只是針對1張圖片進行預測    \n",
    "        elif K.image_data_format() == 'channels_last' and image.shape != (1, IMAGE_SIZE, IMAGE_SIZE, 3):\n",
    "            image = resize_image(image)\n",
    "            image = image.reshape((1, IMAGE_SIZE, IMAGE_SIZE, 3))                    \n",
    "        \n",
    "        #浮點並歸一化\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        \n",
    "        #給出輸入屬於各個類別的概率，函式會給出輸入影象概率各為多少\n",
    "        result = self.model.predict_classes(image) \n",
    "        print('result:', self.model.predict(image))\n",
    "        print(\"===========face_predict==========\")\n",
    "        print(self.model.predict(image)[0][result[0]])\n",
    "#         result = self.model.predict(image)\n",
    "        print('result:', result)\n",
    "        possibility = self.model.predict(image)[0][result[0]]\n",
    "#         if(result)\n",
    "        #給出類別預測\n",
    "        if possibility > 0.7 :  \n",
    "            return result[0]\n",
    "        #返回類別預測結果\n",
    "        return -1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    dataset = Dataset('./face/')    \n",
    "    dataset.load()\n",
    "    \n",
    "    model = Model()\n",
    "    model.build_model(dataset)\n",
    "    \n",
    "    #先前新增的測試build_model()函式的程式碼\n",
    "    model.build_model(dataset)\n",
    "\n",
    "    #測試訓練函式的程式碼\n",
    "    model.train(dataset)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    dataset = Dataset('./face/')    \n",
    "    dataset.load()\n",
    "    \n",
    "    model = Model()\n",
    "    model.build_model(dataset)\n",
    "    print(\"======dataset======\")\n",
    "    print(dataset)\n",
    "    model.train(dataset)\n",
    "    model.save_model(file_path = './model/haarcascade2.face.model.h5')\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':    \n",
    "    dataset = Dataset('./face/')    \n",
    "    dataset.load()\n",
    "\n",
    "    \n",
    "    #評估模型\n",
    "    model = Model()\n",
    "    model.load_model(file_path = './model/haarcascade2.face.model.h5')\n",
    "    model.evaluate(dataset)    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
