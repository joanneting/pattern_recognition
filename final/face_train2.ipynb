{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from load_dataset.ipynb\n",
      "{0: 'LinTzuTing', 1: 'abarnvbtwb', 2: 'Theodora', 3: 'aelfnikyqj'}\n",
      "+++++++===\n",
      "./face/\n",
      "(3347, 64, 64, 3)\n",
      "[1 1 1 ... 2 2 2]\n",
      "3347\n",
      "64 64 3\n",
      "2342 train samples\n",
      "1005 valid samples\n",
      "1674 test samples\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 24,901,508\n",
      "Trainable params: 24,848,388\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 24,901,508\n",
      "Trainable params: 24,848,388\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "2342\n",
      "Epoch 1/5\n",
      "74/74 [==============================] - 305s 4s/step - loss: 0.1602 - acc: 0.9641 - val_loss: 62.3311 - val_acc: 0.0716\n",
      "Epoch 2/5\n",
      "74/74 [==============================] - 319s 4s/step - loss: 0.0430 - acc: 0.9915 - val_loss: 1.3103 - val_acc: 0.2896\n",
      "Epoch 3/5\n",
      "74/74 [==============================] - 310s 4s/step - loss: 0.0719 - acc: 0.9893 - val_loss: 2.3990 - val_acc: 0.2896\n",
      "Epoch 4/5\n",
      "74/74 [==============================] - 303s 4s/step - loss: 0.0259 - acc: 0.9936 - val_loss: 1.4650 - val_acc: 0.2896\n",
      "Epoch 5/5\n",
      "74/74 [==============================] - 304s 4s/step - loss: 0.0112 - acc: 0.9983 - val_loss: 18.6160 - val_acc: 0.2896\n",
      "{0: 'LinTzuTing', 1: 'abarnvbtwb', 2: 'Theodora', 3: 'aelfnikyqj'}\n",
      "+++++++===\n",
      "./face/\n",
      "(6694, 64, 64, 3)\n",
      "[1 1 1 ... 2 2 2]\n",
      "6694\n",
      "64 64 3\n",
      "4685 train samples\n",
      "2009 valid samples\n",
      "3347 test samples\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 24,901,508\n",
      "Trainable params: 24,848,388\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "======dataset======\n",
      "<__main__.Dataset object at 0x00000222FE496AC0>\n",
      "4685\n",
      "Epoch 1/5\n",
      "147/147 [==============================] - 615s 4s/step - loss: 0.3101 - acc: 0.9748 - val_loss: 1.5413 - val_acc: 0.5650\n",
      "Epoch 2/5\n",
      "147/147 [==============================] - 626s 4s/step - loss: 0.0828 - acc: 0.9932 - val_loss: 1.1673 - val_acc: 0.5650\n",
      "Epoch 3/5\n",
      "147/147 [==============================] - 616s 4s/step - loss: 0.0148 - acc: 0.9970 - val_loss: 1.1822 - val_acc: 0.5650\n",
      "Epoch 4/5\n",
      " 86/147 [================>.............] - ETA: 4:19 - loss: 0.0466 - acc: 0.9890"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-463580af54e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"======dataset======\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./model/haarcascade2.face.model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-463580af54e7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, dataset, batch_size, nb_epoch, data_augmentation)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;31m#             early_stopping = EarlyStopping(monitor='val_loss',patience=100)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;31m#             reduce_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m             self.model.fit(datagen.flow(dataset.train_images, dataset.train_labels,\n\u001b[0m\u001b[0;32m    238\u001b[0m                                                    batch_size = batch_size),\n\u001b[0;32m    239\u001b[0m \u001b[1;31m#                             steps_per_epoch = dataset.train_images.shape[0]/batch_size,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\.conda\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\.conda\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\TensorFlow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D,GlobalAveragePooling2D,BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# import os\n",
    "# import sys\n",
    "# sys.path.insert(0, os.path.abspath('../final/'))\n",
    "\n",
    "# from load_dataset import load_dataset, resize_image, IMAGE_SIZE\n",
    "import Ipynb_importer\n",
    "from load_dataset import load_dataset, resize_image, IMAGE_SIZE\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, path_name):\n",
    "        #訓練集\n",
    "        self.train_images = None\n",
    "        self.train_labels = None\n",
    "        \n",
    "        #驗證集\n",
    "        self.valid_images = None\n",
    "        self.valid_labels = None\n",
    "        \n",
    "        #測試集\n",
    "        self.test_images  = None            \n",
    "        self.test_labels  = None\n",
    "        \n",
    "        #資料集載入路徑\n",
    "        self.path_name    = path_name\n",
    "        \n",
    "        #當前庫採用的維度順序\n",
    "        self.input_shape = None\n",
    "        \n",
    "    #載入資料集並按照交叉驗證的原則劃分資料集並進行相關預處理工作\n",
    "    def load(self, img_rows = IMAGE_SIZE, img_cols = IMAGE_SIZE, \n",
    "             img_channels = 3, nb_classes =4):\n",
    "        peoples = {}\n",
    "        with open('./faceDetail.csv', newline='') as csvfile:\n",
    "                  # 讀取 CSV 檔案內容\n",
    "            rows = csv.reader(csvfile)\n",
    "            for row in rows :\n",
    "                if(row[1] == 'label') :\n",
    "                    continue\n",
    "                peoples[int(row[1])] = row[0]\n",
    "        nb_classes = len(peoples)\n",
    "        print(peoples)\n",
    "        #載入資料集到記憶體\n",
    "        images, labels = load_dataset(self.path_name)        \n",
    "        \n",
    "        train_images, valid_images, train_labels, valid_labels = train_test_split(images, labels, test_size = 0.3, random_state = random.randint(0, 100))        \n",
    "        _, test_images, _, test_labels = train_test_split(images, labels, test_size = 0.5, random_state = random.randint(0, 100))                \n",
    "        \n",
    "        #當前的維度順序如果為'th'，則輸入圖片資料時的順序為：channels,rows,cols，否則:rows,cols,channels\n",
    "#                          channels_first                channels,width,height    width、height、channels\n",
    "        #這部分程式碼就是根據keras庫要求的維度順序重組訓練資料集\n",
    "        if K.image_data_format() == 'channels_first':# 高版本使用\n",
    "#         if K.image_dim_ordering() == 'th':# 低版本使用\n",
    "            train_images = train_images.reshape(train_images.shape[0], img_channels, img_rows, img_cols)\n",
    "            valid_images = valid_images.reshape(valid_images.shape[0], img_channels, img_rows, img_cols)\n",
    "            test_images = test_images.reshape(test_images.shape[0], img_channels, img_rows, img_cols)\n",
    "            self.input_shape = (img_channels, img_rows, img_cols)            \n",
    "        else:\n",
    "            print(img_rows, img_cols, img_channels);\n",
    "            train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, img_channels)\n",
    "            valid_images = valid_images.reshape(valid_images.shape[0], img_rows, img_cols, img_channels)\n",
    "            test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, img_channels)\n",
    "            self.input_shape = (img_rows, img_cols, img_channels)            \n",
    "            \n",
    "        #輸出訓練集、驗證集、測試集的數量\n",
    "        print(train_images.shape[0], 'train samples')\n",
    "        print(valid_images.shape[0], 'valid samples')\n",
    "        print(test_images.shape[0], 'test samples')\n",
    "\n",
    "        #我們的模型使用categorical_crossentropy作為損失函式，因此需要根據類別數量nb_classes將\n",
    "        #類別標籤進行one-hot編碼使其向量化，在這裡我們的類別只有兩種，經過轉化後標籤資料變為二維\n",
    "        train_labels = np_utils.to_categorical(train_labels, nb_classes)                        \n",
    "        valid_labels = np_utils.to_categorical(valid_labels, nb_classes)            \n",
    "        test_labels = np_utils.to_categorical(test_labels, nb_classes)                        \n",
    "\n",
    "        #畫素資料浮點化以便歸一化\n",
    "        train_images = train_images.astype('float32')            \n",
    "        valid_images = valid_images.astype('float32')\n",
    "        test_images = test_images.astype('float32')\n",
    "\n",
    "        #將其歸一化,影象的各畫素值歸一化到0~1區間\n",
    "        train_images /= 255\n",
    "        valid_images /= 255\n",
    "        test_images /= 255            \n",
    "\n",
    "        self.train_images = train_images\n",
    "        self.valid_images = valid_images\n",
    "        self.test_images  = test_images\n",
    "        self.train_labels = train_labels\n",
    "        self.valid_labels = valid_labels\n",
    "        self.test_labels  = test_labels\n",
    "            \n",
    "#CNN網路模型類            \n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.model = None \n",
    "        \n",
    "    #建立模型\n",
    "    def build_model(self, dataset, nb_classes = 4):\n",
    "        #構建一個空的網路模型，它是一個線性堆疊模型，各神經網路層會被順序新增，專業名稱為序貫模型或線性堆疊模型\n",
    "        self.model = Sequential() \n",
    "        peoples = {}\n",
    "        with open('./faceDetail.csv', newline='') as csvfile:\n",
    "                  # 讀取 CSV 檔案內容\n",
    "            rows = csv.reader(csvfile)\n",
    "            for row in rows :\n",
    "                if(row[1] == 'label') :\n",
    "                    continue\n",
    "                peoples[int(row[1])] = row[0]\n",
    "        nb_classes = len(peoples)\n",
    "        #以下程式碼將順序新增CNN網路需要的各層，一個add就是一個網路層\n",
    "        #                           (輸出維度,)\n",
    "          \n",
    "#         self.model.add(Convolution2D(32, 3, 3,padding='same', \n",
    "#                                      input_shape = dataset.input_shape))    #1 2維卷積層\n",
    "#         self.model.add(Activation('relu'))                                  #2 啟用函式層\n",
    "        self.model.add(ResNet50(include_top=False, weights='imagenet', input_tensor=None,pooling='max', input_shape = dataset.input_shape))\n",
    "        self.model.add(Activation('relu'))   \n",
    "        self.model.add(Dropout(0.25))\n",
    "        \n",
    "#         self.model.add(Convolution2D(32, 3, 3))                             #3 2維卷積層                             \n",
    "#         self.model.add(Activation('relu'))                                  #4 啟用函式層\n",
    "        \n",
    "#         self.model.add(MaxPooling2D(pool_size=(2, 2)))                      #5 池化層\n",
    "#         self.model.add(Dropout(0.))                                       #6 Dropout層\n",
    "\n",
    "#         self.model.add(Convolution2D(64, 3, 3, padding='same'))         #7  2維卷積層\n",
    "#         self.model.add(Activation('relu'))                                  #8  啟用函式層\n",
    "        \n",
    "#         self.model.add(Convolution2D(64, 3, 3))                             #9  2維卷積層\n",
    "#         self.model.add(Activation('relu'))                                  #10 啟用函式層\n",
    "        \n",
    "#         self.model.add(MaxPooling2D(pool_size=(2, 2)))                      #11 池化層\n",
    "#         self.model.add(Dropout(0.25))                                       #12 Dropout層\n",
    "#         self.model.add(GlobalAveragePooling2D(name='average_pool'))\n",
    "        self.model.add(Flatten())                                           #13 Flatten層\n",
    "        self.model.add(Dense(512))                                          #14 Dense層,又被稱作全連線層\n",
    "        self.model.add(Activation('relu'))                                  #15 啟用函式層   \n",
    "#         self.model.add(BatchNormalization())\n",
    "        self.model.add(Dropout(0.25)) \n",
    "        self.model.add(Dense(512))                                          #14 Dense層,又被稱作全連線層\n",
    "        self.model.add(Activation('relu'))         \n",
    "        \n",
    "        \n",
    "        self.model.add(Dropout(0.25))                                        #16 Dropout層\n",
    "#         self.model.add(Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.01))) \n",
    "        \n",
    "        self.model.add(Dense(nb_classes))                                   #17 Dense層\n",
    "        self.model.add(Activation('softmax'))                               #18 分類層，輸出最終結果\n",
    "        \n",
    "        self.model.summary()\n",
    "#     def scheduler(epoch):\n",
    "#     # 前5个epoch学习率保持不变，5个epoch后学习率按比例衰减\n",
    "#     if epoch < 5:\n",
    "#         return 0.001\n",
    "#     else:\n",
    "#         lr = 0.001 * tf.math.exp(0.1 * (5 - epoch))\n",
    "#         return lr.numpy()\n",
    "    \n",
    "\n",
    "    #訓練模型\n",
    "    def train(self, dataset, batch_size = 32, nb_epoch = 5, data_augmentation = True):\n",
    "        \n",
    "        learning_rate = 0.001\n",
    "        decay_rate = 1e-6\n",
    "        \n",
    "        self.model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=learning_rate,  decay=decay_rate, amsgrad=True), metrics=['acc'])\n",
    "#         self.model.compile(loss='categorical_crossentropy',optimizer=Adam(), metrics=['acc'])\n",
    "        #輸出模型概況\n",
    "#         sgd = SGD(lr = 0.01, decay = 1e-6, \n",
    "#                   momentum = 0.9, nesterov = True) #採用SGD+momentum的優化器進行訓練，首先生成一個優化器物件  \n",
    "#         self.model.compile(loss='categorical_crossentropy',\n",
    "#                            optimizer=sgd,\n",
    "#                            metrics=['accuracy'])   #完成實際的模型配置工作\n",
    "        \n",
    "        #不使用資料提升，所謂的提升就是從我們提供的訓練資料中利用旋轉、翻轉、加噪聲等方法創造新的\n",
    "        #訓練資料，有意識的提升訓練資料規模，增加模型訓練量\n",
    "        if not data_augmentation:            \n",
    "            self.model.fit(dataset.train_images,\n",
    "                           dataset.train_labels,\n",
    "                           batch_size = batch_size,\n",
    "                           epochs = nb_epoch,\n",
    "                           validation_data = (dataset.valid_images, dataset.valid_labels),\n",
    "                           shuffle = True)\n",
    "        #使用實時資料提升\n",
    "        else:            \n",
    "            #定義資料生成器用於資料提升，其返回一個生成器物件datagen，datagen每被呼叫一\n",
    "            #次其生成一組資料（順序生成），節省記憶體，其實就是python的資料生成器\n",
    "            datagen = ImageDataGenerator(\n",
    "                featurewise_center = False,             #是否使輸入資料去中心化（均值為0），\n",
    "                samplewise_center  = False,             #是否使輸入資料的每個樣本均值為0\n",
    "                featurewise_std_normalization = False,  #是否資料標準化（輸入資料除以資料集的標準差）\n",
    "                samplewise_std_normalization  = False,  #是否將每個樣本資料除以自身的標準差\n",
    "                zca_whitening = False,                  #是否對輸入資料施以ZCA白化\n",
    "                rotation_range = 10,                    #資料提升時圖片隨機轉動的角度(範圍為0～180)\n",
    "                rescale = 1./255,\n",
    "                width_shift_range  = 0.1,               #資料提升時圖片水平偏移的幅度（單位為圖片寬度的佔比，0~1之間的浮點數）\n",
    "                height_shift_range = 0.1,               #同上，只不過這裡是垂直\n",
    "                horizontal_flip = False,                 #是否進行隨機水平翻轉\n",
    "                vertical_flip = False,                   #是否進行隨機垂直翻轉\n",
    "                fill_mode = 'constant')                 \n",
    "\n",
    "            #計算整個訓練樣本集的數量以用於特徵值歸一化、ZCA白化等處理\n",
    "            datagen.fit(dataset.train_images) \n",
    "            test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "            test_datagen.fit(dataset.valid_images)\n",
    "            print(dataset.train_images.shape[0])\n",
    "            #利用生成器開始訓練模型\n",
    "#             self.model.fit(dataset.train_images,\n",
    "#                            dataset.train_labels,\n",
    "#                            batch_size = batch_size,\n",
    "#                            epochs = nb_epoch,\n",
    "#                            validation_data = (dataset.valid_images, dataset.valid_labels),\n",
    "#                            shuffle = True)\n",
    "           \n",
    "#             early_stopping = EarlyStopping(monitor='val_loss',patience=100) \n",
    "#             reduce_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "            self.model.fit(datagen.flow(dataset.train_images, dataset.train_labels,\n",
    "                                                   batch_size = batch_size),\n",
    "#                             steps_per_epoch = dataset.train_images.shape[0]/batch_size,\n",
    "                            epochs = nb_epoch,\n",
    "                            validation_data = test_datagen.flow(dataset.valid_images, dataset.valid_labels,batch_size = batch_size),\n",
    "                            shuffle = True)    \n",
    "#              self.model.fit(datagen.flow(dataset.train_images, dataset.train_labels,\n",
    "#                                                    batch_size = batch_size),\n",
    "# #                             steps_per_epoch = dataset.train_images.shape[0]/batch_size,\n",
    "#                             epochs = nb_epoch,\n",
    "#                             validation_data = (dataset.valid_images, dataset.valid_labels),\n",
    "#                             shuffle = True)    \n",
    "    \n",
    "    MODEL_PATH = './haarcascade2.face.model.h5'\n",
    "    def save_model(self, file_path = MODEL_PATH):\n",
    "         self.model.save(file_path)\n",
    " \n",
    "    def load_model(self, file_path = MODEL_PATH):\n",
    "         self.model = load_model(file_path)\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "         score = self.model.evaluate(dataset.test_images, dataset.test_labels, verbose = 1)\n",
    "         print(\"%s: %.2f%%\" % (self.model.metrics_names[1], score[1] * 100))\n",
    "\n",
    "    #識別人臉\n",
    "    def face_predict(self, image):    \n",
    "        #依然是根據後端系統確定維度順序\n",
    "        if K.image_data_format() == 'channels_first' and image.shape != (1, 3, IMAGE_SIZE, IMAGE_SIZE):\n",
    "            image = resize_image(image)                             #尺寸必須與訓練集一致都應該是IMAGE_SIZE x IMAGE_SIZE\n",
    "            image = image.reshape((1, 3, IMAGE_SIZE, IMAGE_SIZE))   #與模型訓練不同，這次只是針對1張圖片進行預測    \n",
    "        elif K.image_data_format() == 'channels_last' and image.shape != (1, IMAGE_SIZE, IMAGE_SIZE, 3):\n",
    "            image = resize_image(image)\n",
    "            image = image.reshape((1, IMAGE_SIZE, IMAGE_SIZE, 3))                    \n",
    "        \n",
    "        #浮點並歸一化\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        \n",
    "        #給出輸入屬於各個類別的概率，函式會給出輸入影象概率各為多少\n",
    "        result = self.model.predict_classes(image) \n",
    "        print('result:', self.model.predict(image))\n",
    "        print(\"===========face_predict==========\")\n",
    "        print(self.model.predict(image)[0][result[0]])\n",
    "#         result = self.model.predict(image)\n",
    "        print('result:', result)\n",
    "        possibility = self.model.predict(image)[0][result[0]]\n",
    "#         if(result)\n",
    "        #給出類別預測\n",
    "        if possibility > 0.7 :  \n",
    "            return result[0]\n",
    "        #返回類別預測結果\n",
    "        return -1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    dataset = Dataset('./face/')    \n",
    "    dataset.load()\n",
    "    \n",
    "    model = Model()\n",
    "    model.build_model(dataset)\n",
    "    \n",
    "    #先前新增的測試build_model()函式的程式碼\n",
    "    model.build_model(dataset)\n",
    "\n",
    "    #測試訓練函式的程式碼\n",
    "    model.train(dataset)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    dataset = Dataset('./face/')    \n",
    "    dataset.load()\n",
    "    \n",
    "    model = Model()\n",
    "    model.build_model(dataset)\n",
    "    print(\"======dataset======\")\n",
    "    print(dataset)\n",
    "    model.train(dataset)\n",
    "    model.save_model(file_path = './model/haarcascade2.face.model.h5')\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':    \n",
    "    dataset = Dataset('./face/')    \n",
    "    dataset.load()\n",
    "\n",
    "    \n",
    "    #評估模型\n",
    "    model = Model()\n",
    "    model.load_model(file_path = './model/haarcascade2.face.model.h5')\n",
    "    model.evaluate(dataset)    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
